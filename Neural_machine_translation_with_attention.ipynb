{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "Machine translation is the task of automatically converting source text in one language to text in another language. In a machine translation task, the input already consists of a sequence of symbols in some language, and the computer program must convert this into a sequence of symbols in another language. Given a sequence of symbols in a source language, there is no one single best translation of that sequence to another language. This is because of the natural ambiguity and flexibility of human language. This makes the challenge of automatic machine translation difficult, perhaps one of the most difficult in artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation with Attention\n",
    "To translate a sentence from a language to another one, a human translator reads the sentence part by part, and generates part of translation. ANeural machine translation with attention like a human translator looks at the sentence part by part. To generate each part of translation, the attention mechanism tells a Neural Machine Translation model where it should pay attention to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a Neural Machine Translation with Attention model that can be used to translate from one language to another, like Farsi to English translation. However, training on real-world translation data can take days of training on GPUs. To evaluate the model, I used it for date translation task. \n",
    "We will have the network learn to converts Human Readable dates like '28th of March, 1985 ' to Machine Readable format '1985-03-28'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Date dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages to generate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from keras.utils import to_categorical\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Faker package to generate random fake dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(1988)\n",
    "random.seed(1988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define format of the data we would like to generate\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this if you want it to work with another language\n",
    "LOCALE = 'en_US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates a fake date using a random format picked from our list FORMATS defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fake_date():\n",
    "    \"\"\"\n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS),\n",
    "                                     locale=LOCALE)  \n",
    "        human_readable = human_readable.lower().replace(',', '')\n",
    "        machine_readable = dt.isoformat()\n",
    "\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tuesday march 28 1978', '1978-03-28', datetime.date(1978, 3, 28))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_fake_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Let's run the following cells to generates the dataset of 20k human readable dates and their equivalent, standardized, machine readable dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:02<00:00, 9587.08it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 20000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = generate_dataset(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've generated:\n",
    "- `dataset`: a list of tuples of (human readable date, machine readable date).\n",
    "- `human_vocab`: a python dictionary mapping all characters used in the human readable dates to an integer-valued index.\n",
    "- `machine_vocab`: a python dictionary mapping all characters used in machine readable dates to an integer-valued index. \n",
    "    - **Note**: These indices are not necessarily consistent with `human_vocab`. \n",
    "- `inv_machine_vocab`: the inverse dictionary of `machine_vocab`, mapping from indices back to characters. \n",
    "\n",
    "Let's take a look at the first 5 entries of dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tuesday march 28 1978', '1978-03-28'),\n",
       " ('26 january 2007', '2007-01-26'),\n",
       " ('29 01 12', '2012-01-29'),\n",
       " ('thursday february 7 1980', '1980-02-07'),\n",
       " ('february 12 1975', '1975-02-12')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our human readable vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '/': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'y': 34,\n",
       " '<unk>': 35,\n",
       " '<pad>': 36}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our machine readable vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at inverse of the machine readable vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the data and map the raw text data into the index values. \n",
    "- We will set Tx=30 \n",
    "    - We assume Tx is the maximum length of the human readable date.\n",
    "    - If we get a longer input, we would have to truncate it.\n",
    "- We will set Ty=10\n",
    "    - \"YYYY-MM-DD\" is 10 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (20000, 30)\n",
      "Y.shape: (20000, 10)\n",
      "Xoh.shape: (20000, 30, 37)\n",
      "Yoh.shape: (20000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples of preprocessed training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 26 january 2007\n",
      "Target date: 2007-01-26\n",
      "\n",
      "Source after preprocessing (indices): [ 5  9  0 22 13 25 31 13 28 34  0  5  3  3 10 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [3 1 1 8 0 1 2 0 3 7]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model \n",
    "Here are some properties of the model that you may notice: \n",
    "- There are two separate LSTMs in this model : pre-attention and post-attention LSTMs on both sides of the attention mechanism. \n",
    "- *pre-attention* LSTM is a Bi-directional LSTM. Output sequence (hidden states) of this LSTM is input of the attention mechanism.\n",
    "     - The pre-attention Bi-LSTM goes through $T_x$ time steps\n",
    "- *post-attention* LSTM is a LSTM that comes after the attention mechanism.\n",
    "     - The post-attention LSTM goes through $T_y$ time steps. \n",
    "- The attention mechanism computes the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one_step_attention\n",
    "* The inputs to the one_step_attention at time step $t$ are:\n",
    "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
    "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
    "* one_step_attention computes:\n",
    "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
    "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
    "    \n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all the packages you will need for definign the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Layers of the attention mechanism \n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\"\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis \n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor1(concat)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas,a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(X)\n",
    "    \n",
    "    post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "    output_layer = Dense(len(machine_vocab), activation=softmax)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "    \n",
    "        context = one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(inputs=context, initial_state=[s, c])\n",
    "        out = output_layer(s)\n",
    "        outputs.append(out)\n",
    "    \n",
    "   \n",
    "    model = Model(inputs=[X,s0,c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the following cell to create your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tenserflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tenserflow/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 44s 2ms/step - loss: 12.9768 - dense_4_loss: 2.3566 - dense_4_acc: 0.7376 - dense_4_acc_1: 0.7970 - dense_4_acc_2: 0.4300 - dense_4_acc_3: 0.1443 - dense_4_acc_4: 0.9953 - dense_4_acc_5: 0.5648 - dense_4_acc_6: 0.1884 - dense_4_acc_7: 0.9844 - dense_4_acc_8: 0.3772 - dense_4_acc_9: 0.1590\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 5.8542 - dense_4_loss: 1.3612 - dense_4_acc: 0.9733 - dense_4_acc_1: 0.9745 - dense_4_acc_2: 0.7795 - dense_4_acc_3: 0.5267 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9473 - dense_4_acc_6: 0.6117 - dense_4_acc_7: 0.9996 - dense_4_acc_8: 0.6868 - dense_4_acc_9: 0.5219\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 2.8018 - dense_4_loss: 0.5161 - dense_4_acc: 0.9781 - dense_4_acc_1: 0.9823 - dense_4_acc_2: 0.8873 - dense_4_acc_3: 0.8534 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9717 - dense_4_acc_6: 0.8436 - dense_4_acc_7: 0.9998 - dense_4_acc_8: 0.8116 - dense_4_acc_9: 0.8428\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 1.6995 - dense_4_loss: 0.2771 - dense_4_acc: 0.9842 - dense_4_acc_1: 0.9886 - dense_4_acc_2: 0.9366 - dense_4_acc_3: 0.9427 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9756 - dense_4_acc_6: 0.9086 - dense_4_acc_7: 0.9999 - dense_4_acc_8: 0.8576 - dense_4_acc_9: 0.9208\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 1.1749 - dense_4_loss: 0.1915 - dense_4_acc: 0.9897 - dense_4_acc_1: 0.9943 - dense_4_acc_2: 0.9652 - dense_4_acc_3: 0.9803 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9774 - dense_4_acc_6: 0.9296 - dense_4_acc_7: 0.9999 - dense_4_acc_8: 0.9036 - dense_4_acc_9: 0.9455\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.8781 - dense_4_loss: 0.1453 - dense_4_acc: 0.9945 - dense_4_acc_1: 0.9979 - dense_4_acc_2: 0.9785 - dense_4_acc_3: 0.9925 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9796 - dense_4_acc_6: 0.9420 - dense_4_acc_7: 0.9999 - dense_4_acc_8: 0.9322 - dense_4_acc_9: 0.9595\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.6944 - dense_4_loss: 0.1118 - dense_4_acc: 0.9977 - dense_4_acc_1: 0.9992 - dense_4_acc_2: 0.9877 - dense_4_acc_3: 0.9966 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9808 - dense_4_acc_6: 0.9508 - dense_4_acc_7: 0.9999 - dense_4_acc_8: 0.9480 - dense_4_acc_9: 0.9715\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.5757 - dense_4_loss: 0.0924 - dense_4_acc: 0.9988 - dense_4_acc_1: 0.9996 - dense_4_acc_2: 0.9928 - dense_4_acc_3: 0.9974 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9823 - dense_4_acc_6: 0.9568 - dense_4_acc_7: 0.9999 - dense_4_acc_8: 0.9559 - dense_4_acc_9: 0.9781\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.4800 - dense_4_loss: 0.0748 - dense_4_acc: 0.9992 - dense_4_acc_1: 0.9997 - dense_4_acc_2: 0.9962 - dense_4_acc_3: 0.9975 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9837 - dense_4_acc_6: 0.9624 - dense_4_acc_7: 0.9998 - dense_4_acc_8: 0.9650 - dense_4_acc_9: 0.9845\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.4130 - dense_4_loss: 0.0637 - dense_4_acc: 0.9996 - dense_4_acc_1: 0.9998 - dense_4_acc_2: 0.9978 - dense_4_acc_3: 0.9979 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9846 - dense_4_acc_6: 0.9676 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9716 - dense_4_acc_9: 0.9870\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.3594 - dense_4_loss: 0.0551 - dense_4_acc: 0.9998 - dense_4_acc_1: 0.9999 - dense_4_acc_2: 0.9981 - dense_4_acc_3: 0.9980 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9853 - dense_4_acc_6: 0.9749 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9782 - dense_4_acc_9: 0.9904\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.3082 - dense_4_loss: 0.0459 - dense_4_acc: 0.9998 - dense_4_acc_1: 0.9999 - dense_4_acc_2: 0.9985 - dense_4_acc_3: 0.9980 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9860 - dense_4_acc_6: 0.9804 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9838 - dense_4_acc_9: 0.9924\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.2705 - dense_4_loss: 0.0402 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9989 - dense_4_acc_3: 0.9981 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9864 - dense_4_acc_6: 0.9833 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9879 - dense_4_acc_9: 0.9936\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.2401 - dense_4_loss: 0.0352 - dense_4_acc: 0.9999 - dense_4_acc_1: 0.9999 - dense_4_acc_2: 0.9990 - dense_4_acc_3: 0.9982 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9866 - dense_4_acc_6: 0.9862 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9909 - dense_4_acc_9: 0.9951\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.2134 - dense_4_loss: 0.0303 - dense_4_acc: 1.0000 - dense_4_acc_1: 0.9999 - dense_4_acc_2: 0.9991 - dense_4_acc_3: 0.9982 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9872 - dense_4_acc_6: 0.9883 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9928 - dense_4_acc_9: 0.9959\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.1958 - dense_4_loss: 0.0273 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9993 - dense_4_acc_3: 0.9982 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9872 - dense_4_acc_6: 0.9896 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9933 - dense_4_acc_9: 0.9964\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1747 - dense_4_loss: 0.0234 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9995 - dense_4_acc_3: 0.9982 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9877 - dense_4_acc_6: 0.9914 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9955 - dense_4_acc_9: 0.9972\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1592 - dense_4_loss: 0.0212 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9997 - dense_4_acc_3: 0.9982 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9885 - dense_4_acc_6: 0.9922 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9966 - dense_4_acc_9: 0.9973\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1464 - dense_4_loss: 0.0186 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9997 - dense_4_acc_3: 0.9983 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9886 - dense_4_acc_6: 0.9929 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9971 - dense_4_acc_9: 0.9978\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.1354 - dense_4_loss: 0.0168 - dense_4_acc: 1.0000 - dense_4_acc_1: 1.0000 - dense_4_acc_2: 0.9997 - dense_4_acc_3: 0.9983 - dense_4_acc_4: 1.0000 - dense_4_acc_5: 0.9889 - dense_4_acc_6: 0.9938 - dense_4_acc_7: 1.0000 - dense_4_acc_8: 0.9978 - dense_4_acc_9: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1307d0a58>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))\n",
    "model.fit([Xoh, s0, c0], outputs, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "source: 5 April 09\n",
      "output: 2009-04-05\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-31\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "Example_dates = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in Example_dates:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = source.reshape((1, ) + source.shape)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tenserflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
